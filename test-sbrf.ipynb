{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34acf43e-a76c-441b-bb3e-313f0e3a34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d815360d-f456-4201-82f9-ede0e1cdfa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    # .master('dev-java.home.lan')\n",
    "    .master('local[4]')\n",
    "    .appName('mySpark')\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a56791dc-917e-4caf-8a0a-46cf71b2094e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+----------+----------+----------+\n",
      "|  lc|    ln|    lns|activeFlag|        sd|        ed|\n",
      "+----+------+-------+----------+----------+----------+\n",
      "|lc-5|ln-5-2|lns-5-2|         1|2020-01-03|2079-06-06|\n",
      "|lc-1|ln-1-1|lns-1-1|         1|2020-12-25|2021-01-01|\n",
      "|lc-1|ln-1-3|lns-1-3|         1|2021-02-01|2079-06-06|\n",
      "|lc-1|ln-1-2|lns-1-2|         1|2021-01-02|2021-01-31|\n",
      "|lc-2|ln-2-3|lns-2-3|         0|2024-12-05|2099-01-01|\n",
      "|lc-2|ln-2-1|lns-2-1|         0|2020-12-02|2024-12-01|\n",
      "|lc-2|ln-2-2|lns-2-2|         0|2024-12-02|2024-12-04|\n",
      "|lc-3|ln-3-1|lns-3-1|         0|2024-12-02|2019-01-02|\n",
      "|lc-4|ln-4-1|lns-4-1|         1|2020-01-01|2021-01-02|\n",
      "|lc-5|ln-5-1|lns-5-1|         1|2020-01-01|2021-01-02|\n",
      "+----+------+-------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType, TimestampType, BooleanType\n",
    "\n",
    "sm = StructType(fields = [\n",
    "    StructField(\"lc\", StringType()),\n",
    "    StructField(\"ln\", StringType()),\n",
    "    StructField(\"lns\", StringType()),\n",
    "    StructField(\"activeFlag\", StringType()),\n",
    "    StructField(\"sd\", DateType()),\n",
    "    StructField(\"ed\", DateType()),\n",
    "    #StructField(\"cd\", StringType()),\n",
    "    #StructField(\"ca\", StringType()),\n",
    "    #StructField(\"snapshot_\", StringType()),\n",
    "    #StructField(\"cv\", TimestampType()),\n",
    "    #StructField(\"cl\", IntegerType())\n",
    "])\n",
    "df = spark.read.csv(\"sbrf.csv\", schema=sm, sep=',')\n",
    "#df.printSchema()\n",
    "df.show(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9270c4f4-6e1c-4a3e-b5c9-0d414fb7c18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+----------+----------+----------+-----+\n",
      "|lc  |ln    |lns    |activeFlag|sd        |ed        |af   |\n",
      "+----+------+-------+----------+----------+----------+-----+\n",
      "|lc-1|ln-1-1|lns-1-1|1         |2020-12-25|2021-01-01|true |\n",
      "|lc-1|ln-1-2|lns-1-2|1         |2021-01-02|2021-01-31|true |\n",
      "|lc-1|ln-1-3|lns-1-3|1         |2021-02-01|2079-06-06|true |\n",
      "|lc-2|ln-2-1|lns-2-1|0         |2020-12-02|2024-12-01|false|\n",
      "|lc-2|ln-2-2|lns-2-2|0         |2024-12-02|2024-12-04|false|\n",
      "|lc-2|ln-2-3|lns-2-3|0         |2024-12-05|2099-01-01|false|\n",
      "|lc-3|ln-3-1|lns-3-1|0         |2024-12-02|2019-01-02|false|\n",
      "|lc-4|ln-4-1|lns-4-1|1         |2020-01-01|2021-01-02|true |\n",
      "|lc-5|ln-5-1|lns-5-1|1         |2020-01-01|2021-01-02|true |\n",
      "|lc-5|ln-5-2|lns-5-2|1         |2020-01-03|2079-06-06|true |\n",
      "+----+------+-------+----------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"af\", F.col(\"activeFlag\").cast(BooleanType()))\n",
    "#df_ = df.withColumn(\"dtn\", F.to_timestamp(\"dt1\", \"dd-MM-yyyy HH:mm:ss\"))\n",
    "# df_.printSchema()\n",
    "df.orderBy([\"lc\",\"ln\"]).show(25, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9ed9c82b-4ef7-409b-8bd8-d9f624155c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+----------+----------+----------+-----+----------+\n",
      "|  lc|    ln|    lns|activeFlag|        sd|        ed|   af|        nv|\n",
      "+----+------+-------+----------+----------+----------+-----+----------+\n",
      "|lc-1|ln-1-1|lns-1-1|         1|2020-12-25|2021-01-01| true|2021-01-02|\n",
      "|lc-1|ln-1-2|lns-1-2|         1|2021-01-02|2021-01-31| true|2021-02-01|\n",
      "|lc-1|ln-1-3|lns-1-3|         1|2021-02-01|2079-06-06| true|      NULL|\n",
      "|lc-2|ln-2-1|lns-2-1|         0|2020-12-02|2024-12-01|false|2024-12-02|\n",
      "|lc-2|ln-2-2|lns-2-2|         0|2024-12-02|2024-12-04|false|2024-12-05|\n",
      "|lc-2|ln-2-3|lns-2-3|         0|2024-12-05|2099-01-01|false|      NULL|\n",
      "|lc-4|ln-4-1|lns-4-1|         1|2020-01-01|2021-01-02| true|      NULL|\n",
      "|lc-5|ln-5-1|lns-5-1|         1|2020-01-01|2021-01-02| true|2020-01-03|\n",
      "|lc-5|ln-5-2|lns-5-2|         1|2020-01-03|2079-06-06| true|      NULL|\n",
      "+----+------+-------+----------+----------+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "w = Window.partitionBy(\"lc\").orderBy(\"sd\")\n",
    "#w = Window.orderBy(\"ln\")\n",
    "df1 = df.withColumn(\"nv\", F.lead(\"sd\").over(w))\n",
    "df.withColumn(\"nv\", F.lead(\"sd\").over(w)).where('1=1 and sd <= ed').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "10250af0-2b65-461f-b026-b213e0526b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+----------+----------+----------+-----+----------+\n",
      "|lc  |ln    |lns    |activeFlag|sd        |ed        |af   |nv        |\n",
      "+----+------+-------+----------+----------+----------+-----+----------+\n",
      "|lc-1|ln-1  |lns-1  |1         |2020-12-25|2021-01-01|true |2021-01-02|\n",
      "|lc-1|ln-1-2|lns-1  |1         |2021-01-02|2021-01-31|true |2021-02-01|\n",
      "|lc-1|ln-1-3|lns-1  |1         |2021-02-01|2099-01-01|true |NULL      |\n",
      "|lc-2|ln-2  |lns-2  |0         |2020-12-02|2024-12-01|false|2024-12-02|\n",
      "|lc-2|ln-2-1|lns-2  |0         |2024-12-02|2099-01-01|false|2024-12-02|\n",
      "|lc-2|ln-2-2|lns-2  |0         |2024-12-02|2099-01-01|false|NULL      |\n",
      "|lc-3|ln-3  |lns-3  |0         |2024-12-02|2019-01-02|false|NULL      |\n",
      "|lc-4|ln-4  |lns-4-1|1         |2020-01-01|2021-01-02|true |NULL      |\n",
      "|lc-5|ln-4  |lns-4-1|1         |2020-01-01|2021-01-02|true |2020-01-03|\n",
      "|lc-5|ln-4  |lns-4-1|1         |2020-01-03|2079-06-06|true |NULL      |\n",
      "+----+------+-------+----------+----------+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "085f24f9-8cf0-495f-bb82-5dd07130beb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+----------+----------+----------+-----+----------+\n",
      "|  lc|    ln|    lns|activeFlag|        sd|        ed|   af|        nv|\n",
      "+----+------+-------+----------+----------+----------+-----+----------+\n",
      "|lc-1|  ln-1|  lns-1|         1|2020-12-25|2021-01-01| true|2021-01-02|\n",
      "|lc-1|ln-1-2|  lns-1|         1|2021-01-02|2021-01-31| true|2021-02-01|\n",
      "|lc-1|ln-1-3|  lns-1|         1|2021-02-01|2099-01-01| true|      NULL|\n",
      "|lc-2|  ln-2|  lns-2|         0|2020-12-02|2024-12-01|false|2024-12-02|\n",
      "|lc-2|ln-2-1|  lns-2|         0|2024-12-02|2099-01-01|false|2024-12-02|\n",
      "|lc-2|ln-2-2|  lns-2|         0|2024-12-02|2099-01-01|false|      NULL|\n",
      "|lc-3|  ln-3|  lns-3|         0|2024-12-02|2019-01-02|false|      NULL|\n",
      "|lc-4|  ln-4|lns-4-1|         1|2020-01-01|2021-01-02| true|      NULL|\n",
      "|lc-5|  ln-4|lns-4-1|         1|2020-01-01|2021-01-02| true|2020-01-03|\n",
      "|lc-5|  ln-4|lns-4-1|         1|2020-01-03|2079-06-06| true|      NULL|\n",
      "+----+------+-------+----------+----------+----------+-----+----------+\n",
      "\n",
      "+----+------+-------+----------+----------+----------+-----+----------+\n",
      "|  lc|    ln|    lns|activeFlag|        sd|        ed|   af|        nv|\n",
      "+----+------+-------+----------+----------+----------+-----+----------+\n",
      "|lc-1|  ln-1|  lns-1|         1|2020-12-25|2021-01-01| true|2021-01-02|\n",
      "|lc-1|ln-1-2|  lns-1|         1|2021-01-02|2021-01-31| true|2021-02-01|\n",
      "|lc-1|ln-1-3|  lns-1|         1|2021-02-01|2099-01-01| true|      NULL|\n",
      "|lc-2|  ln-2|  lns-2|         0|2020-12-02|2024-12-01|false|2024-12-02|\n",
      "|lc-2|ln-2-1|  lns-2|         0|2024-12-02|2099-01-01|false|2024-12-02|\n",
      "|lc-2|ln-2-2|  lns-2|         0|2024-12-02|2099-01-01|false|      NULL|\n",
      "|lc-4|  ln-4|lns-4-1|         1|2020-01-01|2021-01-02| true|      NULL|\n",
      "|lc-5|  ln-4|lns-4-1|         1|2020-01-01|2021-01-02| true|2020-01-03|\n",
      "|lc-5|  ln-4|lns-4-1|         1|2020-01-03|2079-06-06| true|      NULL|\n",
      "+----+------+-------+----------+----------+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"view1\")\n",
    "spark.sql(\"select *, lead(sd) over(partition by lc order by sd) as nv from view1 where 1=1\").show()\n",
    "dft1 = spark.sql(\"select *, lead(sd) over(partition by lc order by sd) as nv from view1 where 1=1 and sd <= ed and lc is not null\")\n",
    "dft1.show(25)\n",
    "dft1.createOrReplaceTempView(\"view2\")\n",
    "#dft2 = spark.sql(\"select * from view2\")\n",
    "#dft2.show(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "339ceb03-b0c9-461c-a9ec-2e1914316b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+----------+----------+----------+-----+----+-----+\n",
      "|  lc|    ln|    lns|activeFlag|        sd|        ed|   af|  nv|  af1|\n",
      "+----+------+-------+----------+----------+----------+-----+----+-----+\n",
      "|lc-1|ln-1-3|  lns-1|         1|2021-02-01|2099-01-01| true|NULL|false|\n",
      "|lc-2|ln-2-2|  lns-2|         0|2024-12-02|2099-01-01|false|NULL| true|\n",
      "|lc-3|  ln-3|  lns-3|         0|2024-12-02|2019-01-02|false|NULL| true|\n",
      "|lc-4|  ln-4|lns-4-1|         1|2020-01-01|2021-01-02| true|NULL|false|\n",
      "+----+------+-------+----------+----------+----------+-----+----+-----+\n",
      "\n",
      "+----+------+-------+----------+----------+----------+-----+----+\n",
      "|  lc|    ln|    lns|activeFlag|        sd|        ed|   af|  nv|\n",
      "+----+------+-------+----------+----------+----------+-----+----+\n",
      "|lc-1|  ln-1|  lns-1|         1|2020-12-25|2021-01-01| true|lc-1|\n",
      "|lc-1|ln-1-2|  lns-1|         1|2021-01-02|2021-01-31| true|lc-1|\n",
      "|lc-1|ln-1-3|  lns-1|         1|2021-02-01|2099-01-01| true|NULL|\n",
      "|lc-2|  ln-2|  lns-2|         0|2020-12-02|2024-12-01|false|lc-2|\n",
      "|lc-2|ln-2-1|  lns-2|         0|2024-12-02|2099-01-01|false|lc-2|\n",
      "|lc-2|ln-2-2|  lns-2|         0|2024-12-02|2099-01-01|false|NULL|\n",
      "|lc-4|  ln-4|lns-4-1|         1|2020-01-01|2021-01-02| true|NULL|\n",
      "|lc-5|  ln-4|lns-4-1|         1|2020-01-01|2021-01-02| true|lc-5|\n",
      "|lc-5|  ln-4|lns-4-1|         1|2020-01-03|2079-06-06| true|NULL|\n",
      "+----+------+-------+----------+----------+----------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df1.show()\n",
    "df1.createOrReplaceTempView(\"view3\")\n",
    "#df1.show()\n",
    "dft3 = spark.sql(\"select *, case af when true then false else true end as af1 from view3 where nv is null and ed <> to_date('2079-06-06')\")\n",
    "dft3.show()\n",
    "\n",
    "e = spark.sql(\"with pre_r as (select lc,ln,lns,activeFlag,sd,ed,CAST(activeFlag as BOOLEAN) as af,lead(lc) over(partition by lc order by sd) as nv from view3 where 1=1 and sd <= ed and lc is not null) select * from pre_r\")\n",
    "df4 = e.select('*')\n",
    "df4.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "54df4502-d298-4b68-ab03-73a20d3f60c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+----------+----------+----------+-----+----+\n",
      "|  lc|    ln|    lns|activeFlag|        sd|        ed|   af|  nv|\n",
      "+----+------+-------+----------+----------+----------+-----+----+\n",
      "|lc-1|ln-1-3|  lns-1|         1|2021-02-01|2099-01-01| true|NULL|\n",
      "|lc-2|ln-2-2|  lns-2|         0|2024-12-02|2099-01-01|false|NULL|\n",
      "|lc-4|  ln-4|lns-4-1|         1|2020-01-01|2021-01-02| true|NULL|\n",
      "+----+------+-------+----------+----------+----------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.createOrReplaceTempView(\"view4\")\n",
    "df4.select(\"*\").where(\"nv is NULL and ed <> to_date('2079-06-06')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7291b6d0-c4e1-45a4-a8d1-2af5d9b88449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
